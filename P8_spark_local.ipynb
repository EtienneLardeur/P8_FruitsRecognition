{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we handle through pySpark, sql & ml, the featurization and its dimension reduction of an image collection stored on S3. <br/>\n",
    "The local execution of this notebooks lead to an OOM - java heap space issue, due to lack of memory resources while trying a PCA transformation. <br/>\n",
    "Aim is to demonstrate the ability to build a scalable architecture to perform expected transformations, and enable upcoming fast growth of the image collection keeping a viable computationnal time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# context & session\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "# from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyarrow\n",
    "pyarrow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usefull packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "# deal with image\n",
    "# import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data handling\n",
    "from pyspark.sql.functions import element_at, split, input_file_name\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "# from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from typing import Iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml tasks\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# core featurizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cloud\n",
    "# import boto.s3\n",
    "import boto3\n",
    "import s3fs\n",
    "import fsspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### time monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process, elapsed time: 0.00s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "stop = time.perf_counter()\n",
    "print(f'process, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### local home path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/etienne'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "home = str(Path.home())\n",
    "home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud or Local: Connect to S3 storage bucket & Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu-west-3'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws-logs-629250884158-eu-west-3\n",
      "oc-p8-fruits-storage\n"
     ]
    }
   ],
   "source": [
    "# thanks to the proper set of .aws folder which ensure relevant rights\n",
    "s3 = boto3.resource('s3', region_name=boto3.Session().region_name)\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3client.get_object(Bucket='oc-p8-fruits-storage', Key='Sample/Fig/27_100.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = response['Body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.response.StreamingBody at 0x7f518bcf2250>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = conn.list_objects(Bucket='oc-p8-fruits-storage', Prefix='Sample')['Contents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample/\n",
      "Sample/Eggplant/89_100.jpg\n",
      "Sample/Eggplant/r_233_100.jpg\n",
      "Sample/Eggplant/r_273_100.jpg\n",
      "Sample/Eggplant/r_99_100.jpg\n",
      "Sample/Fig/192_100.jpg\n",
      "Sample/Fig/27_100.jpg\n",
      "Sample/Fig/r_202_100.jpg\n",
      "Sample/Fig/r_39_100.jpg\n"
     ]
    }
   ],
   "source": [
    "for f in contents:\n",
    "    print(f['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_local switch either to local execution or remote (S3)\n",
    "is_local = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path value according to execution location\n",
    "def create_path(is_local_):\n",
    "    if is_local_ == False:\n",
    "        # set the proper folder as input : 'Sample/' only or full 'Training/'\n",
    "        bucket='oc-p8-fruits-storage'\n",
    "        folder='Sample/'\n",
    "        path_='s3a://{}/{}'.format(bucket, folder)\n",
    "    else:\n",
    "        path_='/mnt/c/users/etien/datascience/p8/inputs/applesample/**'\n",
    "    return path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_path = create_path(is_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3a://oc-p8-fruits-storage/Sample/'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='oc-p8-fruits-storage', key='test.txt')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('test.txt', 'rb')\n",
    "s3.Bucket('oc-p8-fruits-storage').put_object(Key='test.txt', Body=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original upload of images into storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# bulk rename to remove spaces out of folders name\\n# rational : spark.read.format(\"image\").load(path) requires no space in path\\n# warning : do not apply until checking the parent location\\ndef rename_folders(parent):\\n    for path, folders, _ in os.walk(parent):\\n        for i in range(len(folders)):\\n            new_name = folders[i].replace(\\' \\', \\'_\\')\\n            os.rename(os.path.join(path, folders[i]), os.path.join(path, new_name))\\n            folders[i] = new_name\\n# warning : only one time\\n# rename_folders(\\'Inputs/Training\\')\\n# upload S3 through awscli : aws s3 cp Inputs s3://oc-p8-fruits-storage/ --recursive '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# bulk rename to remove spaces out of folders name\n",
    "# rational : spark.read.format(\"image\").load(path) requires no space in path\n",
    "# warning : do not apply until checking the parent location\n",
    "def rename_folders(parent):\n",
    "    for path, folders, _ in os.walk(parent):\n",
    "        for i in range(len(folders)):\n",
    "            new_name = folders[i].replace(' ', '_')\n",
    "            os.rename(os.path.join(path, folders[i]), os.path.join(path, new_name))\n",
    "            folders[i] = new_name\n",
    "# warning : only one time\n",
    "# rename_folders('Inputs/Training')\n",
    "# upload S3 through awscli : aws s3 cp Inputs s3://oc-p8-fruits-storage/ --recursive '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scT.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure the spark Context\n",
    "conf = (\n",
    "    SparkConf().set(\n",
    "        'spark.executor.extraJavaOptions', '-Dcom.amazonaws.services.s3.enableV4=true'\n",
    "    ).set(\n",
    "        'spark.driver.extraJavaOptions', '-Dcom.amazonaws.services.s3.enableV4=true'\n",
    "    ).set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:2.7.2')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "scT = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "scT.setSystemProperty('com.amazonaws.services.s3.enableV4', 'true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf = scT._jsc.hadoopConfiguration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadoopConf.set('fs.s3a.awsAccessKeyId', 'AKIAZFASGQI7KFKLNEAQ')\n",
    "hadoopConf.set('fs.s3a.awsSecretAccessKey', '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')\n",
    "hadoopConf.set('fs.s3a.endpoint', 'eu-west-3.amazonaws.com')\n",
    "hadoopConf.set('com.amazonaws.services.s3a.enableV4', 'true')\n",
    "hadoopConf.set('fs.s3a.impl', 'org.apache.hadoop.fs.s3a.S3AFileSystem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:2.7.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a Spark session\n",
    "spark = SparkSession(scT).builder.master('local[*]').appName('P8').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://desktop-gp5v58f.home:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>P8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f518c36d820>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open spark UI for app monitoring\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.id', 'local-1611233142490'),\n",
       " ('spark.driver.host', 'desktop-gp5v58f.home'),\n",
       " ('spark.driver.port', '64709'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-Dcom.amazonaws.services.s3.enableV4=true'),\n",
       " ('spark.app.name', 'P8'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-Dcom.amazonaws.services.s3.enableV4=true'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check wether arrow should be enabled by this setting\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o219.load.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2197)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:46)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n\t... 25 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-376f810fe42d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m's3a://oc-p8-fruits-storage/Sample/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o219.load.\n: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2197)\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:2654)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:2667)\n\tat org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:94)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:2703)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:2685)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:373)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:295)\n\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:46)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:297)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:286)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:286)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:232)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found\n\tat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101)\n\tat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195)\n\t... 25 more\n"
     ]
    }
   ],
   "source": [
    "spark.read.format('image').load('s3a://oc-p8-fruits-storage/Sample/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subsection to demonstrate the OOM Java heap space failure\n",
    "OOM occurs over a given size of vectors matrix (2800 < nb_col < 3000, even with tiny nb_row). <br/>\n",
    "As repartition could be enhanced it increase computational time but with no substantial effect on OOM issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the Spark DataFrame as vectors matrix\n",
    "def test_vec_df(nb_row, nb_col, nb_repartition):\n",
    "    pdf = pd.DataFrame(np.random.rand(nb_row, nb_col))\n",
    "    df = spark.createDataFrame(pdf)\n",
    "    input_cols = df.columns\n",
    "    df = df.repartition(nb_repartition)\n",
    "    assembler = VectorAssembler(\n",
    "    inputCols=input_cols,\n",
    "    outputCol='features')\n",
    "    df_vec = assembler.transform(df)\n",
    "    return df_vec.select('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|         pcafeatures|\n",
      "+--------------------+--------------------+\n",
      "|[0.66883280043084...|[-0.4534974392755...|\n",
      "|[0.48144827969251...|[-0.0774219628919...|\n",
      "|[0.68764074105559...|[-0.5591360400226...|\n",
      "|[0.18382291134109...|[-0.7053331058853...|\n",
      "|[0.89293760972500...|[0.15553662044367...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create input & try to reduce with PCA\n",
    "test_df = test_vec_df(2200, 512, 4)\n",
    "pca = PCA(k=16, inputCol=\"features\", outputCol=\"pcafeatures\")\n",
    "model = pca.fit(test_df)\n",
    "results_df = model.transform(test_df)\n",
    "results_df.show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check wether aws should be loaded into os.environ or through spark.conf.set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages com.amazonaws:aws-java-sdk:1.7.4,\\\n",
    "org.apache.hadoop:hadoop-aws:2.7.3,\\\n",
    "com.amazonaws:aws-java-sdk-s3:1.11.762 pyspark-shell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore through Spark Dataframe with 'image' format\n",
    "nb this format appears to be irrelevant once trying to read binary contents, see below the alternate technique to build Spark Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case Cloud\n",
    "def get_cloud_path(path_):\n",
    "    '''collect path_list_ from on S3 bucket path_ through s3fs library'''\n",
    "    path_list= pd.DataFrame(columns=['path'])\n",
    "    sub_folder = fs.ls(path_)\n",
    "    for fold in sub_folder: \n",
    "        path_list = path_list.append(pd.DataFrame(fs.ls('s3n://'+fold), columns=['path']), ignore_index=True)\n",
    "    print(path_list.shape[0], 'images')\n",
    "    return path_list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the spark_df, with explicit path stored for further use \n",
    "def load_data(path_, is_local_):\n",
    "    ''' building of a spark df out of a spark.read of images + label extraction'''\n",
    "    # monitor time\n",
    "    start = time.perf_counter()\n",
    "    if is_local_ == False:\n",
    "        df_img = spark.createDataFrame(get_cloud_path(path_))\n",
    "    else:\n",
    "        df_img = spark.read.format('image').load(path_) # remove spaces of folder's name first\n",
    "        df_img = df_img.withColumn('label', element_at(split(df_img['image.origin'], \"/\"), -2))\n",
    "    stop = time.perf_counter()\n",
    "    print(f'data loader, elapsed time: {stop - start:0.2f}s')\n",
    "    return df_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loader, elapsed time: 3.43s\n"
     ]
    }
   ],
   "source": [
    "spark_df = load_data(work_path, is_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+\n",
      "|               image|         label|\n",
      "+--------------------+--------------+\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|\n",
      "+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "show - max 5 items, elapsed time: 0.30s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "spark_df.show(5, True)\n",
    "stop = time.perf_counter()\n",
    "print(f'show - max 5 items, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+---------+----+--------------------+--------------+\n",
      "|              origin|height|width|nChannels|mode|                data|         label|\n",
      "+--------------------+------+-----+---------+----+--------------------+--------------+\n",
      "|file:///mnt/c/use...|   100|  100|        3|  16|[FF FF FF FF FF F...|Apple_Golden_1|\n",
      "|file:///mnt/c/use...|   100|  100|        3|  16|[FF FF FF FF FF F...|Apple_Golden_1|\n",
      "|file:///mnt/c/use...|   100|  100|        3|  16|[FF FF FF FF FF F...|Apple_Golden_1|\n",
      "|file:///mnt/c/use...|   100|  100|        3|  16|[FF FF FF FF FF F...|Apple_Golden_1|\n",
      "|file:///mnt/c/use...|   100|  100|        3|  16|[FF FF FF FF FF F...|Apple_Golden_1|\n",
      "+--------------------+------+-----+---------+----+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.select(\n",
    "    'image.origin',\n",
    "    'image.height',\n",
    "    'image.width',\n",
    "    'image.nChannels',\n",
    "    'image.mode',\n",
    "    'image.data',\n",
    "    'label'\n",
    ").show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x7F23A184AFD0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first image\n",
    "# note that we need to get a bytearray from image.data\n",
    "Image.fromarray(\n",
    "    np.array(\n",
    "        spark_df.first().asDict()['image']['data']\n",
    "    ).reshape(100, 100, 3)[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion to Pandas, elapsed time: 14.13s\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2134 entries, 0 to 2133\n",
      "Columns: 2 entries, data to label\n",
      "dtypes: object(2)\n",
      "memory usage: 61.3 MB\n"
     ]
    }
   ],
   "source": [
    "# get memory_usage\n",
    "# if large, use only fraction for rough approximation with: sample = spark_df.sample(fraction = 0.01)\n",
    "start = time.perf_counter()\n",
    "pdf = spark_df.select('image.data', 'label').toPandas()\n",
    "stop = time.perf_counter()\n",
    "print(f'conversion to Pandas, elapsed time: {stop - start:0.2f}s')\n",
    "pdf.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2134, 2)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of a CNN as feature extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.microsoft.com/zh-tw/azure/databricks/_static/notebooks/deep-learning/deep-learning-transfer-learning-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model for featurization, last layers truncated.\n",
    "# nb. spark workers need to access the model and its weights\n",
    "conv_base = VGG16(\n",
    "    include_top=False,\n",
    "    weights=None,\n",
    "    pooling='max',\n",
    "    input_shape=(100, 100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 100, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 100, 100, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 100, 100, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 50, 50, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 50, 50, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 25, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 25, 25, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 25, 25, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 12, 12, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 12, 12, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# verify that the top layer is removed\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights as broadcasted variable over nodes (provide a copy to each node)\n",
    "conv_base_weights = spark.sparkContext.broadcast(conv_base.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set weights\n",
    "# conv_base.set_weights(conv_base_weights.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make conv_base callable\n",
    "def conv_base_init():\n",
    "    # returns a VGG 16 model with top layer removed and broadcasted weights\n",
    "    conv_base = VGG16(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        pooling='max',\n",
    "        input_shape=(100, 100, 3))\n",
    "    # error if sparkcontext as it will be called on workers and not only drivers\n",
    "    # conv_base_weights = sc.broadcast(conv_base.get_weights())\n",
    "    conv_base.set_weights(conv_base_weights.value)\n",
    "    return conv_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define image loading and featurization logic in a Pandas UDF\n",
    "This notebook defines the logic in steps, building up to the Pandas UDF. \n",
    "The call stack is:\n",
    "- pandas UDF\n",
    "    - featurize a pd.Series of images\n",
    "        - preprocess one image\n",
    "        \n",
    "This notebook uses the newer Scalar Iterator pandas UDF to amortize the cost of loading large models on workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ! control shape of constructed array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In Spark 3.0, Pandas UDFs can accept an iterator of pandas.Series or pandas.DataFrame so that you can load the model only once instead of loading it for every series in the iterator. <br/>\n",
    " When the number of images rising over the default 10,000 arrow.maxRecordsPerBatch we expect significant speed ups over a pandas scalar UDF because it iterates through batches of pd.Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_path):\n",
    "    path = image_path.replace(\"file://\", \"\")\n",
    "    img = load_img(path)\n",
    "    x = img_to_array(img)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target pandas user defined function to make operation on dataframe with pyspark.sql\n",
    "@pandas_udf('array<double>')\n",
    "def featurize(images_data_iter: Iterator[pd.DataFrame]) -> Iterator[pd.DataFrame]:\n",
    "    # load model outside of for loop\n",
    "    conv_base = conv_base_init()\n",
    "    for image_data_series in images_data_iter:\n",
    "        image_path_series = image_data_series[\"origin\"]\n",
    "        # Apply functions to entire series at once\n",
    "        x = image_path_series.map(preprocess)\n",
    "        x = np.stack(list(x.values))\n",
    "        # option is to enable batch_size\n",
    "        features = conv_base.predict(x)\n",
    "        features_flat = [p.flatten() for p in features]\n",
    "        yield pd.Series(features_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurization, elapsed time: 0.01s\n"
     ]
    }
   ],
   "source": [
    "# apply featurization\n",
    "start = time.perf_counter()\n",
    "featurized_df = spark_df.withColumn('cnn_features', featurize('image'))\n",
    "stop = time.perf_counter()\n",
    "print(f'featurization, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- image: struct (nullable = true)\n",
      " |    |-- origin: string (nullable = true)\n",
      " |    |-- height: integer (nullable = true)\n",
      " |    |-- width: integer (nullable = true)\n",
      " |    |-- nChannels: integer (nullable = true)\n",
      " |    |-- mode: integer (nullable = true)\n",
      " |    |-- data: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- cnn_features: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featurized_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+\n",
      "|               image|         label|        cnn_features|\n",
      "+--------------------+--------------+--------------------+\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46911802887916...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46934741735458...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.44682577252388...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.42899486422538...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.47695738077163...|\n",
      "+--------------------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "featurize, elapsed time: 5.87s\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "featurized_df.show(5, True)\n",
    "stop = time.perf_counter()\n",
    "print(f'featurize, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion to Pandas, elapsed time: 4.62s\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Columns: 3 entries, origin to cnn_features\n",
      "dtypes: object(3)\n",
      "memory usage: 38.4 KB\n"
     ]
    }
   ],
   "source": [
    "# get memory_usage\n",
    "# if large, use only fraction for rough approximation with: sample = spark_df.sample(fraction = 0.01)\n",
    "start = time.perf_counter()\n",
    "pdf = featurized_df.select('image.origin', 'label', 'cnn_features').toPandas()\n",
    "stop = time.perf_counter()\n",
    "print(f'conversion to Pandas, elapsed time: {stop - start:0.2f}s')\n",
    "pdf.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf.cnn_features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform from Arrays into Vectors to perform reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Array to Vectors for PCA\n",
    "array_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df = featurized_df.withColumn('cnn_vectors', array_to_vector_udf('cnn_features'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+\n",
      "|               image|         label|        cnn_features|         cnn_vectors|\n",
      "+--------------------+--------------+--------------------+--------------------+\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46911802887916...|[0.46911802887916...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46934741735458...|[0.46934741735458...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.44682577252388...|[0.44682577252388...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.42899486422538...|[0.42899486422538...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.47695738077163...|[0.47695738077163...|\n",
      "+--------------------+--------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorized_df.show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(vectorized_df.rdd.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize & Apply PCA\n",
    "Results may vary with larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca - to get adequate nb of pcs, elapsed time: 391.60s\n"
     ]
    }
   ],
   "source": [
    "# reduce with PCA - set k Max to determine the adequate nb of principal components\n",
    "start = time.perf_counter()\n",
    "pca = PCA(k=512, inputCol='cnn_vectors', outputCol='pca_vectors')\n",
    "model = pca.fit(vectorized_df)\n",
    "stop = time.perf_counter()\n",
    "print(f'pca - to get adequate nb of pcs, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nb of pc that would explain 80% variance\n",
    "def get_best_k(model_, expl_var):\n",
    "    for c, i in enumerate(np.cumsum(model.explainedVariance)):\n",
    "        if i >= (expl_var / 100):\n",
    "            print('{} principal components are required for {}% explained variance'.format(c, expl_var))\n",
    "            return c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 principal components are required for 80% explained variance\n"
     ]
    }
   ],
   "source": [
    "best_k_ = get_best_k(model, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca - fit best k nb, elapsed time: 322.07s\n"
     ]
    }
   ],
   "source": [
    "# reduce with PCA - set k Max to determine the adequate nb of principal components\n",
    "start = time.perf_counter()\n",
    "best_k_pca = PCA(k=best_k_, inputCol='cnn_vectors', outputCol='pca_vectors')\n",
    "best_k_model = best_k_pca.fit(vectorized_df)\n",
    "stop = time.perf_counter()\n",
    "print(f'pca - fit best k nb, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca - application, elapsed time: 1.00s\n"
     ]
    }
   ],
   "source": [
    "# apply pca reduction\n",
    "start = time.perf_counter()\n",
    "reduced_df = best_k_model.transform(vectorized_df)\n",
    "stop = time.perf_counter()\n",
    "print(f'pca - application, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|               image|         label|        cnn_features|         cnn_vectors|         pca_vectors|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46911802887916...|[0.46911802887916...|[-5.9748932981729...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46934741735458...|[0.46934741735458...|[-5.9379970256293...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.44682577252388...|[0.44682577252388...|[-5.8920138361190...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.42899486422538...|[0.42899486422538...|[-5.9472400533679...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.47695738077163...|[0.47695738077163...|[-5.9657079391003...|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reduced_df.show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inverse transform: from Vectors to Array - i.e. Pandas readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Array to Vectors for PCA\n",
    "vector_to_array_udf = udf(lambda v: v.toArray().tolist(), ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = reduced_df.withColumn('features', vector_to_array_udf('pca_vectors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|               image|         label|        cnn_features|         cnn_vectors|         pca_vectors|            features|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46911802887916...|[0.46911802887916...|[-5.9748932981729...|[-5.974893, -0.35...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.46934741735458...|[0.46934741735458...|[-5.9379970256293...|[-5.937997, -0.44...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.44682577252388...|[0.44682577252388...|[-5.8920138361190...|[-5.892014, -0.44...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.42899486422538...|[0.42899486422538...|[-5.9472400533679...|[-5.94724, -0.403...|\n",
      "|[file:///mnt/c/us...|Apple_Golden_1|[0.47695738077163...|[0.47695738077163...|[-5.9657079391003...|[-5.965708, -0.43...|\n",
      "+--------------------+--------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df.show(5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AWS S3 configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '5Z7X8RCT2JCV9M0W', 'HostId': '1L1s4iDCK3P5NIJ8gLgMQInw2YH7jG1pWO8+vRNFP/9z7yU+Jjr8caDn/WJguSmil7K97I6plFA=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': '1L1s4iDCK3P5NIJ8gLgMQInw2YH7jG1pWO8+vRNFP/9z7yU+Jjr8caDn/WJguSmil7K97I6plFA=', 'x-amz-request-id': '5Z7X8RCT2JCV9M0W', 'date': 'Thu, 21 Jan 2021 11:33:03 GMT', 'content-type': 'application/xml', 'transfer-encoding': 'chunked', 'server': 'AmazonS3'}, 'RetryAttempts': 0}, 'Owner': {'ID': 'efc0d1f6df781e765ddecee33d630957f621d5acb562f763e8717286153cc073'}, 'Grants': [{'Grantee': {'ID': 'efc0d1f6df781e765ddecee33d630957f621d5acb562f763e8717286153cc073', 'Type': 'CanonicalUser'}, 'Permission': 'FULL_CONTROL'}]}\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "result = s3.get_bucket_acl(Bucket='oc-p8-fruits-storage')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.conf.set('spark.jars.packages', 'org.apache.hadoop:hadoop-aws:2.7.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# write remote\\nstart = time.perf_counter()\\nresults_df.write.parquet(\"s3://oc-p8-fruits-storage/Output/featurized_sample\", mode=\"overwrite\")\\nstop = time.perf_counter()\\nprint(f\\'write remote, elapsed time: {stop - start:0.2f}s\\')\\n'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# write remote\n",
    "start = time.perf_counter()\n",
    "results_df.write.parquet(\"s3://oc-p8-fruits-storage/Output/featurized_sample\", mode=\"overwrite\")\n",
    "stop = time.perf_counter()\n",
    "print(f'write remote, elapsed time: {stop - start:0.2f}s')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write local, elapsed time: 224.09s\n"
     ]
    }
   ],
   "source": [
    "# write local results on parquet file\n",
    "start = time.perf_counter()\n",
    "final_df.write.mode('overwrite').parquet('/mnt/c/users/etien/datascience/p8/outputs/featurized_sample')\n",
    "stop = time.perf_counter()\n",
    "print(f'write local, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# read remote results from parquet file\\nstart = time.perf_counter()\\nresults_df = pd.read_parquet('s3://oc-p8-fruits-storage/Output/featurized_sample', engine='pyarrow')\\nstop = time.perf_counter()\\nprint(f'read remote, elapsed time: {stop - start:0.2f}s')\\n\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# read remote results from parquet file\n",
    "start = time.perf_counter()\n",
    "results_df = pd.read_parquet('s3://oc-p8-fruits-storage/Output/featurized_sample', engine='pyarrow')\n",
    "stop = time.perf_counter()\n",
    "print(f'read remote, elapsed time: {stop - start:0.2f}s')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read local, elapsed time: 10.95s\n"
     ]
    }
   ],
   "source": [
    "# read local results from parquet file\n",
    "start = time.perf_counter()\n",
    "pd_final_df = pd.read_parquet('/mnt/c/users/etien/datascience/p8/outputs/featurized_sample', engine='pyarrow')\n",
    "stop = time.perf_counter()\n",
    "print(f'read local, elapsed time: {stop - start:0.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2134 entries, 0 to 2133\n",
      "Columns: 6 entries, image to features\n",
      "dtypes: object(6)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "pd_final_df.info(verbose=False, memory_usage=\"deep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "      <th>cnn_features</th>\n",
       "      <th>cnn_vectors</th>\n",
       "      <th>pca_vectors</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'origin': 'file:///mnt/c/users/etien/datascie...</td>\n",
       "      <td>Apple_Golden_1</td>\n",
       "      <td>[0.46911802887916565, 0.2628188133239746, 0.06...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>[-5.974893, -0.35795605, 1.6537114, 0.33222234...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'origin': 'file:///mnt/c/users/etien/datascie...</td>\n",
       "      <td>Apple_Golden_1</td>\n",
       "      <td>[0.46934741735458374, 0.27231505513191223, 0.0...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>[-5.937997, -0.44844365, 1.6200159, 0.29876405...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'origin': 'file:///mnt/c/users/etien/datascie...</td>\n",
       "      <td>Apple_Golden_1</td>\n",
       "      <td>[0.44682577252388, 0.2725944221019745, 0.04801...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>[-5.892014, -0.44113517, 1.6183348, 0.3356398,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'origin': 'file:///mnt/c/users/etien/datascie...</td>\n",
       "      <td>Apple_Golden_1</td>\n",
       "      <td>[0.4289948642253876, 0.27382972836494446, 0.03...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>[-5.94724, -0.40387952, 1.6122764, 0.28537932,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'origin': 'file:///mnt/c/users/etien/datascie...</td>\n",
       "      <td>Apple_Golden_1</td>\n",
       "      <td>[0.47695738077163696, 0.28174883127212524, 0.0...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>{'type': 1, 'size': None, 'indices': None, 'va...</td>\n",
       "      <td>[-5.965708, -0.43102235, 1.61767, 0.31502855, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image           label  \\\n",
       "0  {'origin': 'file:///mnt/c/users/etien/datascie...  Apple_Golden_1   \n",
       "1  {'origin': 'file:///mnt/c/users/etien/datascie...  Apple_Golden_1   \n",
       "2  {'origin': 'file:///mnt/c/users/etien/datascie...  Apple_Golden_1   \n",
       "3  {'origin': 'file:///mnt/c/users/etien/datascie...  Apple_Golden_1   \n",
       "4  {'origin': 'file:///mnt/c/users/etien/datascie...  Apple_Golden_1   \n",
       "\n",
       "                                        cnn_features  \\\n",
       "0  [0.46911802887916565, 0.2628188133239746, 0.06...   \n",
       "1  [0.46934741735458374, 0.27231505513191223, 0.0...   \n",
       "2  [0.44682577252388, 0.2725944221019745, 0.04801...   \n",
       "3  [0.4289948642253876, 0.27382972836494446, 0.03...   \n",
       "4  [0.47695738077163696, 0.28174883127212524, 0.0...   \n",
       "\n",
       "                                         cnn_vectors  \\\n",
       "0  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "1  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "2  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "3  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "4  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "\n",
       "                                         pca_vectors  \\\n",
       "0  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "1  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "2  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "3  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "4  {'type': 1, 'size': None, 'indices': None, 'va...   \n",
       "\n",
       "                                            features  \n",
       "0  [-5.974893, -0.35795605, 1.6537114, 0.33222234...  \n",
       "1  [-5.937997, -0.44844365, 1.6200159, 0.29876405...  \n",
       "2  [-5.892014, -0.44113517, 1.6183348, 0.3356398,...  \n",
       "3  [-5.94724, -0.40387952, 1.6122764, 0.28537932,...  \n",
       "4  [-5.965708, -0.43102235, 1.61767, 0.31502855, ...  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_final_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "# Get back to the original spark dataframe\n",
    "print(len(pd_final_df.features[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
